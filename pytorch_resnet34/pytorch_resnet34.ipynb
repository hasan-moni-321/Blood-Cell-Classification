{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Cell Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2, os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import decomposition\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "import albumentations\n",
    "import pretrainedmodels\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#from pytorchtools import EarlyStopping\n",
    "#from pytorchtools import EarlyStopping\n",
    "#from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of DataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TEST\" \n",
    "\n",
    "CATEGORIES    = ['EOSINOPHIL','LYMPHOCYTE','MONOCYTE','NEUTROPHIL']\n",
    "\n",
    "for k in range(3):\n",
    "    i=0\n",
    "    plt.figure(figsize=(25,15))\n",
    "    for category in CATEGORIES:\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        path=train_dataset_path + '/' + category\n",
    "        image_p=os.listdir(path)\n",
    "        plt.title(category , color='tomato').set_size(15)\n",
    "        plt.axis('off')\n",
    "        image = cv2.imread(os.path.join(path, image_p[k])) \n",
    "        image = image[:, :, [2, 1, 0]] \n",
    "        plt.imshow(image)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = ['/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TRAIN', '/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TEST']\n",
    "CATEGORIES = ['EOSINOPHIL','LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label = []\n",
    "\n",
    "def create_training_data():\n",
    "    for datadir in DATADIR:\n",
    "        for categories in CATEGORIES:\n",
    "            path = os.path.join(datadir, categories)\n",
    "            n_class = CATEGORIES.index(categories)\n",
    "            for images in os.listdir(path):\n",
    "                try:\n",
    "                    image_path = os.path.join(path, images)\n",
    "\n",
    "                    image_label.append([image_path, n_class])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "create_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(image_label, columns=['image_name', 'label'])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df.label.value_counts()\n",
    "sns.barplot(x=count.index, y=count.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, xvalid, Ytrain, yvalid = train_test_split(df.image_name, df.label, test_size=.20)\n",
    "print(Xtrain.shape, xvalid.shape, Ytrain.shape, yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset:\n",
    "    def __init__(self, images, targets, train_data=False):\n",
    "        self.features = images\n",
    "        self.targets = targets\n",
    "\n",
    "        if train_data:\n",
    "            self.aug = albumentations.Compose([\n",
    "                                albumentations.Resize(128, 128, always_apply=True),\n",
    "                                albumentations.ShiftScaleRotate(shift_limit=0.0625,\n",
    "                                                                scale_limit=0.1,\n",
    "                                                                rotate_limit=5,\n",
    "                                                                p=0.9),\n",
    "                                #albumentations.RandomBrightnessContrast(always_apply=False),\n",
    "                                albumentations.RandomRotate90(always_apply=False),\n",
    "                                albumentations.HorizontalFlip(),\n",
    "                                albumentations.VerticalFlip(),\n",
    "                                albumentations.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                                         std=(0.229, 0.224, 0.225), \n",
    "                                                         always_apply=True)              \n",
    "                                                ])\n",
    "\n",
    "        else:\n",
    "            self.aug = albumentations.Compose([\n",
    "                                albumentations.Resize(128, 128, always_apply=True),\n",
    "                                albumentations.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                                                         std=(0.229, 0.224, 0.225),\n",
    "                                                         always_apply=True) \n",
    "                                ])                       \n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets) \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.features[idx]\n",
    "        image = cv2.imread(image)\n",
    "        image = cv2.resize(image, (128,128)).astype(float)\n",
    "        #image = image.reshape(128, 128, 3).astype(float)\n",
    "        #image = Image.fromarray(image).convert(\"RGB\")\n",
    "        image = self.aug(image=np.array(image))['image']\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float) \n",
    "\n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float),\n",
    "            'label': torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_label = Custom_Dataset(\n",
    "                                    images=Xtrain.values, \n",
    "                                    targets=Ytrain.values,\n",
    "                                    train_data=True\n",
    "                                    )\n",
    "valid_feature_label = Custom_Dataset(\n",
    "                                    images=xvalid.values,\n",
    "                                    targets=yvalid.values, \n",
    "                                    train_data=False\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "                        dataset = train_feature_label,\n",
    "                        batch_size = 32,\n",
    "                        shuffle = True, \n",
    "                        num_workers = 4\n",
    "                        )     \n",
    "valid_loader = DataLoader(\n",
    "                        dataset = valid_feature_label,\n",
    "                        batch_size = 32,\n",
    "                        shuffle = False\n",
    "                        ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet34(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Resnet34, self).__init__()\n",
    "        self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')  \n",
    "        self.l0 = nn.Linear(512, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, c, h, w = x.shape\n",
    "        x = self.model.features(x) \n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        op_layer_one = self.l0(x)\n",
    "        return op_layer_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Resnet34()\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer, Criterion, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.3, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Xtrain, data_loader, model, device, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    \n",
    "    total = 0\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "\n",
    "    for bi, data in tqdm(enumerate(data_loader), total=int(len(Xtrain)/data_loader.batch_size)):\n",
    "        image = data['image']\n",
    "        grapheme_root = data['label']\n",
    "        \n",
    "        image = image.to(device, dtype=torch.float)\n",
    "        targets = grapheme_root.to(device, dtype=torch.long) \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        #model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        ##########\n",
    "        #outputs = torch.sigmoid(outputs)\n",
    "        #outputs[outputs >= 0.5] = 1\n",
    "        #accuracy = accuracy_score(targets, outputs.detach().numpy()) \n",
    "        #acc += accuracy\n",
    "        ##########\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "\n",
    "        \n",
    "    train_acc = correct / total\n",
    "    #train_accuracy.append(train_acc) \n",
    "\n",
    "    train_loss = train_loss/total\n",
    "    #train_losses.append(train_loss)\n",
    "\n",
    "    print(\"Epoch: {}  \\tTraining Acc: {:.6f}  \\tTraining Loss: {:.6f}\".format(epoch+1, train_acc, train_loss)) \n",
    "    return train_acc, train_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluation(xvalid, data_loader, model, device, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "\n",
    "    for bi, data in tqdm(enumerate(data_loader), total=int(len(xvalid)/ data_loader.batch_size)):\n",
    "        image = data['image']\n",
    "        grapheme_root = data['label']\n",
    "\n",
    "        image = image.to(device, dtype=torch.float)\n",
    "        targets = grapheme_root.to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        ###############\n",
    "        #outputs = torch.sigmoid(outputs)\n",
    "        #outputs[outputs >= 0.5] = 1   \n",
    "        #accuracy = accuracy_score(targets, outputs.detach().numpy())\n",
    "        #acc += accuracy\n",
    "        ###############\n",
    "        \n",
    "        #acc += (outputs == targets).float().sum()   \n",
    "        #valid_loss += loss.item() * image.size(0)\n",
    "        \n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        \n",
    "\n",
    "    valid_acc = correct/ total\n",
    "    #valid_accuracy.append(valid_acc)\n",
    "\n",
    "    valid_loss = valid_loss / total\n",
    "    #valid_losses.append(valid_loss)\n",
    "\n",
    "\n",
    "    print(\"Epoch: {} \\tValidation Acc: {:.6f}  \\tValidation Loss: {:.6f}\".format(epoch+1, valid_acc, valid_loss))\n",
    "    return valid_acc, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "train_accuracy = []\n",
    "train_losses = []\n",
    "valid_accuracy = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_acc, train_loss = train(Xtrain, train_loader, model, device, optimizer, criterion, scheduler)\n",
    "    valid_acc, valid_loss = evaluation(xvalid, valid_loader, model, device, criterion)\n",
    "    train_accuracy.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    valid_losses.append(valid_loss) \n",
    "\n",
    "    #early_stopping(valid_loss, model) \n",
    "    #if early_stopping.early_stop:\n",
    "        #break \n",
    "\n",
    "print(\"Final train accuracy is :\", np.mean(train_accuracy))\n",
    "print(\"Final train loss is :\", np.mean(train_losses))\n",
    "print(\"Final valid accuracy is :\", np.mean(valid_accuracy))\n",
    "print(\"Final valid loss is :\", np.mean(valid_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Blood_Classification.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TEST_SIMPLE\"\n",
    "CATEGORIES = ['EOSINOPHIL','LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n",
    "\n",
    "test_image_label = []\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    for categories in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, categories)\n",
    "        n_class = CATEGORIES.index(categories)\n",
    "        for images in os.listdir(path):\n",
    "            try:\n",
    "                image_path = os.path.join(path, images)\n",
    "\n",
    "                test_image_label.append([image_path, n_class])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_image_label, columns=['image_name', 'label'])\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_label = Custom_Dataset(\n",
    "                                    images=test_df.image_name.values,\n",
    "                                    targets=test_df.label.values,\n",
    "                                    train_data=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "                        dataset = test_feature_label,\n",
    "                        batch_size = 10,\n",
    "                        shuffle = False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model_trained = Resnet34()\n",
    "model_trained.load_state_dict(torch.load('./Blood_Classification.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        images = data['image']\n",
    "        labels = data['label']\n",
    "        \n",
    "        images = images.to(device, dtype=torch.float) \n",
    "        targets = labels.to(device, dtype=torch.long) \n",
    "        \n",
    "        outputs = model_trained(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    print(\"Test Accuracy of The Model is :\", correct/total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
